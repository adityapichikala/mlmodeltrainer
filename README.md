# AutoML Studio ðŸ¤–

A **No-Code Machine Learning platform** â€” upload a CSV, select a target column, and train models in real-time.

## Tech Stack

| Layer | Technology |
|-------|-----------|
| Frontend | React (Vite) + TailwindCSS + Recharts |
| Backend | FastAPI + Python |
| Database | SQLite (SQLAlchemy) |
| Task Queue | Celery + Redis |
| ML Engine | PyCaret (auto-handles dirty data) |

---

## Quick Start

### Prerequisites
- Python 3.10+
- Node.js 18+
- Redis running on `localhost:6379`

**Start Redis (easiest via Docker):**
```bash
docker run -d -p 6379:6379 redis
```
> **No Docker?** Install Redis via WSL: `sudo apt install redis` then `redis-server`

---

### 1 â€” Backend

```bash
cd backend

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate      # Windows
# source venv/bin/activate  # Mac/Linux

# Install dependencies (~1-2 GB for PyCaret)
pip install -r requirements.txt

# Terminal 1 â€” Start FastAPI
uvicorn main:app --reload --port 8000

# Terminal 2 â€” Start Celery worker (use --pool=solo on Windows)
celery -A worker.celery_app worker --loglevel=info --pool=solo
```

### 2 â€” Frontend

```bash
cd frontend
npm install
npm run dev
```

Open **http://localhost:5173**

---

## Project Structure

```
mlmodeltrainer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI entry point
â”‚   â”œâ”€â”€ config.py            # Settings (Pydantic)
â”‚   â”œâ”€â”€ database.py          # SQLite + SQLAlchemy
â”‚   â”œâ”€â”€ models.py            # Pydantic + ORM models
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ upload.py        # POST /upload
â”‚   â”‚   â”œâ”€â”€ train.py         # POST /train
â”‚   â”‚   â”œâ”€â”€ results.py       # GET /results/{task_id}
â”‚   â”‚   â””â”€â”€ ws.py            # WS /ws/{task_id}
â”‚   â”œâ”€â”€ worker/
â”‚   â”‚   â”œâ”€â”€ celery_app.py    # Celery config
â”‚   â”‚   â””â”€â”€ tasks.py         # train_model task
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ automl.py        # PyCaret pipeline
â”‚   â”‚   â””â”€â”€ detect.py        # Regression/Classification detection
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx           # Router + Layout
        â”œâ”€â”€ context/
        â”‚   â””â”€â”€ AppContext.jsx
        â”œâ”€â”€ hooks/
        â”‚   â””â”€â”€ useWebSocket.js
        â”œâ”€â”€ lib/
        â”‚   â””â”€â”€ api.js
        â”œâ”€â”€ components/
        â”‚   â””â”€â”€ Stepper.jsx
        â””â”€â”€ pages/
            â”œâ”€â”€ Upload.jsx    # Drag-and-drop upload
            â”œâ”€â”€ Configure.jsx # Column preview + target select
            â”œâ”€â”€ Training.jsx  # Live log terminal
            â””â”€â”€ Results.jsx   # Metrics + charts dashboard
```

---

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/upload` | Upload a CSV, returns columns + preview |
| `POST` | `/train` | Start training, returns `task_id` |
| `GET` | `/results/{task_id}` | Fetch job status + results |
| `WS` | `/ws/{task_id}` | Stream training logs |
| `GET` | `/health` | Health check |

---

## Sample Test

Try with the Iris dataset:
```bash
curl -F "file=@iris.csv" http://localhost:8000/upload
# â†’ { "filename": "abc123_iris.csv", "columns": [...] }

curl -X POST http://localhost:8000/train \
  -H "Content-Type: application/json" \
  -d '{"filename": "abc123_iris.csv", "target_col": "species"}'
# â†’ { "task_id": "...", "status": "pending" }
```

---

## Notes

- **Windows + Celery**: use `--pool=solo` flag on the worker
- **PyCaret** automatically handles imputation and one-hot encoding
- Problem type (Regression vs Classification) is **auto-detected**
- The WebSocket closes automatically when training finishes
